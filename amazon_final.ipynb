{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzhrGAagQ3s7",
        "outputId": "76fb5b3e-f655-4b82-8f36-8e3729c39abe"
      },
      "source": [
        "!pip install umap-learn\n",
        "!pip install lightfm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (54.2.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=6296af6daacabee5b5bf09202863d254894a5cb5383abf9b4fd43fdf4e1c4fcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51351 sha256=0900e8f88cf27aad5c6ee46ca5d8bd44dc50132b2924a3670396d1c552e19716\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n",
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/fe/8864d723daa8e5afc74080ce510c30f7ad52facf6a157d4b42dec83dfab4/lightfm-1.16.tar.gz (310kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705350 sha256=1db586965c3210f8e466262cbccbd1f8c4aed9170317dff59e335ea66d7ab348\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/64/d4/673c7277f71ac4c5ad4835b94708c01b653ef2d3aa78ef20aa\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR7bvdd6Q8nE",
        "outputId": "538e1276-78e9-42ec-a0f0-e5817bd22db1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import umap.umap_ as umap\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import preprocessing\n",
        "import spacy\n",
        "import gzip\n",
        "import json\n",
        "import gc\n",
        "import matplotlib.pyplot as plt \n",
        "from scipy.sparse import csr_matrix\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
        "from lightfm import LightFM\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFLxsBXTPUJP",
        "outputId": "09d20418-3947-4b61-8001-e33f221242dc"
      },
      "source": [
        "def prediction(id_asin, id_cust, overall):\n",
        "    interactions_selected = pd.read_excel(\"/content/drive/MyDrive/Проект 'рекомендательная система для магазина'/amazon/interactions.xlsx\")\n",
        "    product_df_selected = pd.read_excel(\"/content/drive/MyDrive/Проект 'рекомендательная система для магазина'/amazon/product_features.xlsx\")\n",
        "    new_row = {'asin': id_asin, 'reviewerID': id_cust, 'overall':overall}\n",
        "    interactions_selected = interactions_selected.append(new_row, ignore_index=True)\n",
        "    chosen_reviewer = interactions_selected['reviewerID'].unique()\n",
        "\n",
        "    index = product_df_selected.loc[product_df_selected['asin'] == id_asin].index\n",
        "    current_overall_mean = float(product_df_selected.iloc[index, 1])\n",
        "    current_count = float(product_df_selected.iloc[index, 2])\n",
        "    product_df_selected.at[index, 'overall_mean'] = round((((current_overall_mean*current_count+overall)/(current_count+1))*2)/2)\n",
        "    product_df_selected.at[index, 'count'] = int(round(((current_count+1)/5.0))*5)\n",
        "\n",
        "    user_book_interaction = pd.pivot_table(interactions_selected, index='reviewerID', columns='asin', values='overall')\n",
        "    user_book_interaction = user_book_interaction.fillna(0)\n",
        "    user_book_interaction_csr = csr_matrix(user_book_interaction.values)\n",
        "    user_book_interaction_csr\n",
        "\n",
        "    user_id = list(user_book_interaction.index)\n",
        "    user_dict = {}\n",
        "    counter = 0 \n",
        "    for i in user_id:\n",
        "        user_dict[i] = counter\n",
        "        counter += 1\n",
        "\n",
        "    books_metadata_selected_transformed = pd.get_dummies(product_df_selected, columns = ['overall_mean', 'count'])\n",
        "    books_metadata_csr = csr_matrix(books_metadata_selected_transformed.drop('asin', axis=1).values)\n",
        "\n",
        "    purchases_list = {}\n",
        "    for i in chosen_reviewer:\n",
        "        temp = interactions_selected[interactions_selected[\"reviewerID\"] == i][\"asin\"].tolist()\n",
        "        purchases_list[i] = temp\n",
        "    \n",
        "    asin_unique = len(list(user_book_interaction.columns))\n",
        "    lens = []\n",
        "    l = list(purchases_list.values())\n",
        "    for i in l:\n",
        "        lens.append(len(i))\n",
        "    lens = sorted(list(set(lens)))\n",
        "    lens = list(set(list(map(lambda x: round(x/5)*5, lens))))\n",
        "    lens_norm = preprocessing.normalize([lens], norm='max')\n",
        "    lens_norm = lens_norm.reshape(-1)\n",
        "\n",
        "    dicti = {}\n",
        "    for i in range(len(lens)):\n",
        "        dicti[lens[i]]=lens_norm[i]\n",
        "\n",
        "    size = len(purchases_list[id_cust])\n",
        "    size = round(size/5)*5\n",
        "    coeff = dicti[size]\n",
        "\n",
        "    answer_wv = Model_WV(purchases_list, asin_unique,coeff)\n",
        "    answer_light = Model_LIGHT(user_book_interaction, id_cust, user_dict, user_book_interaction_csr,books_metadata_csr,coeff)\n",
        "\n",
        "    answer_light = pd.DataFrame(answer_light, columns=['asin','scores'])\n",
        "    answer_wv = pd.DataFrame(answer_wv, columns=['asin','scores'])\n",
        "    answer_wv['scores'] =np.array(answer_light['scores'])+ np.array(answer_wv['scores'])\n",
        "    answer_wv = answer_wv.sort_values(by=['scores'], ascending=False)\n",
        "    return answer_wv\n",
        "\n",
        "def aggregate_vectors(products, model_wv):\n",
        "    product_vec = []\n",
        "    for i in products:\n",
        "        try:\n",
        "            product_vec.append(model_wv[i])\n",
        "        except KeyError:\n",
        "            continue\n",
        "    return np.mean(product_vec, axis=0)\n",
        "\n",
        "def similar_products(v, model_wv, asin_unique):\n",
        "    ms = pd.DataFrame(model_wv.similar_by_vector(v, topn= asin_unique+1), columns=['asin', 'scores'])\n",
        "    ms = ms.sort_values(by=['asin'])\n",
        "    asin = list(ms['asin'])\n",
        "    scores=list(ms['scores'])\n",
        "    lst = []\n",
        "    for i,j in zip(asin, scores):\n",
        "        lst.append([i,j])\n",
        "    return lst\n",
        "\n",
        "\n",
        "\n",
        "def Model_WV(purchases_list, asin_unique, coeff):\n",
        "    model_wv = Word2Vec(window = 10, sg = 1, hs = 0,\n",
        "                    negative = 10, \n",
        "                    alpha=0.03, min_alpha=0.0007, min_count=1)\n",
        "\n",
        "    model_wv.build_vocab(list(purchases_list.values()), progress_per=200)\n",
        "\n",
        "    model_wv.train(purchases_list.values(), total_examples = model_wv.corpus_count, \n",
        "                epochs=10, report_delay=1)\n",
        "    model_wv.init_sims(replace=True)\n",
        "\n",
        "    answer_wv = similar_products(aggregate_vectors(purchases_list[id_cust], model_wv),model_wv,asin_unique)\n",
        "    answer_trans_wv = [x[1] for x in answer_wv]\n",
        "    normalized_answer_wv = preprocessing.normalize([answer_trans_wv],norm='max')\n",
        "    normalized_answer_wv =  normalized_answer_wv.reshape(-1)*coeff\n",
        "    for i in range(len(answer_wv)):\n",
        "        answer_wv[i][1] = normalized_answer_wv[i]\n",
        "    return answer_wv\n",
        "\n",
        "def Model_LIGHT(user_book_interaction, id_cust, user_dict, user_book_interaction_csr,books_metadata_csr,coeff):\n",
        "    model_FM = LightFM(loss='warp', random_state=2016, learning_rate=0.90, no_components=150, user_alpha=0.000005)\n",
        "    model_FM = model_FM.fit(user_book_interaction_csr, epochs=100, num_threads=16, verbose=False)\n",
        "\n",
        "    answer_light = sample_recommendation_user(model_FM, user_book_interaction, id_cust, user_dict,books_metadata_csr)\n",
        "    answer_light_trans = [x[1] for x in answer_light]\n",
        "    normalized_answer_light = preprocessing.normalize([answer_light_trans], norm='max')\n",
        "    normalized_answer_light =  normalized_answer_light.reshape(-1)*(1-coeff)\n",
        "    for i in range(len(answer_light)):\n",
        "        answer_light[i][1] = normalized_answer_light[i]\n",
        "    return answer_light\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sample_recommendation_user(model, interactions, user_id, user_dict, books_metadata_csr,\n",
        "                              threshold = 0,nrec_items = 5):\n",
        "    \n",
        "    n_users, n_items = interactions.shape\n",
        "    user_x = user_dict[user_id]\n",
        "    scores = pd.DataFrame(model.predict(user_x,np.arange(n_items), item_features=books_metadata_csr), columns=['scores'])\n",
        "    scores['asin'] = interactions.columns\n",
        "    scores = scores.sort_values(by=['asin'])\n",
        "    asin = list(scores['asin'])\n",
        "    scores=list(scores['scores'])\n",
        "    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n",
        "                                 [interactions.loc[user_id,:] > threshold].index).sort_values(ascending=False))\n",
        "    for i in known_items:\n",
        "        if i in asin:\n",
        "            ind = asin.index(i)\n",
        "            scores[ind]=0\n",
        "    lst = []\n",
        "    for i,j in zip(asin, scores):\n",
        "        lst.append([i,j])\n",
        "    return lst\n",
        "\n",
        "id_asin = '0441865704'\n",
        "id_cust = \"A2CT25FY12PYNF\"\n",
        "overall = 2\n",
        "answer = prediction(id_asin, id_cust, overall)\n",
        "print(answer['asin'][:5].tolist())\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['B0027YYMU6', 'B0028Y4H1O', 'B006MPRFJQ', 'B000E204LY', 'B000J691BY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8dEQBmtVzhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}